name: Upload Python Spark Job to S3

on:
  push:
    branches:
       - main # Runs on all branches
    paths:
      - 'spark/input_data/pyspark_app.py'  # Only trigger when this file changes
      - 'spark/data_source/**'

jobs:
  lint-pyspark:
    name: Lint PySpark
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python linters
        run: |
          pip install isort flake8

      # - name: Run flake8
      #   run: flake8 ./spark/input_data/data_generator.py

      - name: Run isort
        run: isort ./spark/input_data/data_generator.py

  sync-spark:
    name: Sync spark script to S3
    runs-on: ubuntu-latest
    needs: [lint-pyspark]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
       
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }} 

      - name: Sync Spark Application to S3
        run: |
          aws s3 sync ./spark/input_data s3://${{ secrets.BUCKET_NAME }}/spark_app/ --exclude "*" --include "pyspark_app.py"

        

