name: Upload Python Spark Job to S3

on:
  push:
    branches:
      - '**'  # Runs on all branches
    paths:
      - 'spark/demo.py'  # Only trigger when this file changes

jobs:
  upload-spark-job:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install linting tools
        run: pip install isort flake8

      - name: Run isort (check formatting)
        run: isort --check-only spark/demo.py

      - name: Run flake8 (linting)
        run: flake8 spark/demo.py

      - name: Upload Spark script to S3
        uses: keithweaver/aws-s3-github-action@v1.0.0
        with:
          command: cp
          source: spark/demo.py
          destination: s3://spark-job-data-input/spark_app/demo.py
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: eu-central-1
